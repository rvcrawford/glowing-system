{
  "hash": "f99454c7f1c60c6a994bdb9c340848ef",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Near Infra-Red Spectroscopy Predicts Crude Protein in Hemp Grain\nexecute:\n  echo: false\nauthor:\n  - name: Ryan Crawford\n    # orcid: 0000-0002-0760-5497\n    corresponding: true\n    email: rvc3@cornell.edu\n    # roles:\n    #   - Investigation\n    #   - Project administration\n    #   - Software\n    #   - Visualization\n    affiliations:\n      - name: Cornell University\n        address: 126 Medicago Drive\n        city: Ithaca\n        state: NY\n        postal-code: 14853\n  - name: Jamie Crawford\n    # orcid: 0000-0002-0760-5497\n    corresponding: false\n    # roles:\n    #   - Investigation\n    #   - Project administration\n    #   - Software\n    #   - Visualization\n    affiliations:\n      - name: Cornell University\n        address: 126 Medicago Drive\n        city: Ithaca\n        state: NY\n        postal-code: 14853\n  - name: Lawrence B. Smart\n    # orcid: 0000-0002-7859-8394\n    corresponding: false\n    roles: []\n    affiliations:\n      - name: Cornell AgriTech\n        address: 102 Hedrick Hall\n        city: Geneva\n        state: NY\n        postal-code: 14456\n  - name: Virginia Moore\n    # orcid: 0000-0002-7859-8394\n    corresponding: false\n    roles: []\n    affiliations:\n      - name: Cornell University\n        address: 162 Emerson Hall\n        city: Ithaca\n        state: NY\n        postal-code: 14853    \nkeywords:\n  - Hemp\n  - Grain\n  - Spectroscopy\nabstract: |\n  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nplain-language-summary: |\n  Earthquake data for the island of La Palma from the September 2021 eruption is found ...\nkey-points:\n  - A web scraping script was developed to pull data from the Instituto Geogràphico Nacional into a machine-readable form for analysis\n  - Earthquake events on La Palma are consistent with the presence of both mantle and crustal reservoirs.\ndate: last-modified\nbibliography: \n  - references.bib\n  - grateful-refs.bib\n\ncsl: apa.csl\n# citation:\n#   container-title: Earth and Space Science\nnumber-sections: true\n---\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(data.table)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(prospectr)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[34mprospectr version 0.2.7 -- cakes\u001b[39m\n\u001b[34mcheck the package repository at: https://github.com/l-ramirez-lopez/prospectr\u001b[39m\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(pls)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'pls'\n\nThe following object is masked from 'package:prospectr':\n\n    msc\n\nThe following object is masked from 'package:caret':\n\n    R2\n\nThe following object is masked from 'package:stats':\n\n    loadings\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5      ✔ rsample      1.2.0 \n✔ dials        1.2.1      ✔ tune         1.1.2 \n✔ infer        1.0.6      ✔ workflows    1.1.4 \n✔ modeldata    1.3.0      ✔ workflowsets 1.0.1 \n✔ parsnip      1.2.0      ✔ yardstick    1.3.0 \n✔ recipes      1.0.10     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ data.table::between()    masks dplyr::between()\n✖ scales::discard()        masks purrr::discard()\n✖ dplyr::filter()          masks stats::filter()\n✖ data.table::first()      masks dplyr::first()\n✖ recipes::fixed()         masks stringr::fixed()\n✖ dplyr::lag()             masks stats::lag()\n✖ data.table::last()       masks dplyr::last()\n✖ caret::lift()            masks purrr::lift()\n✖ yardstick::precision()   masks caret::precision()\n✖ yardstick::recall()      masks caret::recall()\n✖ yardstick::sensitivity() masks caret::sensitivity()\n✖ yardstick::spec()        masks readr::spec()\n✖ yardstick::specificity() masks caret::specificity()\n✖ recipes::step()          masks stats::step()\n✖ data.table::transpose()  masks purrr::transpose()\n• Search for functions across packages at https://www.tidymodels.org/find/\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(nlme)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'nlme'\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(kableExtra)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n```\n\n\n:::\n:::\n\n\n**incomplete: may contain errors, run-ons, half-thoughts, etc.**\n\n## INTRODUCTION\n\nHemp (Cannabis sativa L.) is an annual crop with potential uses as a source of food or feed from grain, and bast fiber or hurd from the stalk. Hemp cultivars are commonly grown for one or both purposes and a cultivar may be referred to as a grain, fiber, or dual-purpose type. Because of protein's nutritional importance, the protein content of a grain crop is an prime consideration for researchers, producers, and consumers. Whole hemp grain typically contains approximately 20-30% protein [@ely_industrial_2022; @barta_proteomic_2024; @callaway_hempseed_2004]. Crude protein (CP) is often used as a proxy for the direct measurement of protein concentration and consists of the multiplication of nitrogen concentration by a conversion factor because measuring nitrogen concentration is relatively simple [@hayes_measuring_2020].\n\nNear-infrared spectroscopy (NIRS) technology is rapid, non-destructive, and cheap. It consists of the measurement of NIR radiation reflected and absorbed from a sample (the spectra) and the relation of the spectra to laboratory values for components such as moisture, protein, fat, or fiber [@roberts_near-infrared_2004]. NIRS technology has been used since the 1970's to assess forage CP [@reeves_potential_2012; @williams_application_1975]. A NIRS calibration set often consists of samples from one species grown in many environments encompassing the range of expected values from the analyte or analytes [@chadalavada_nir_2022]. Partial least squares regression (PLSR) is a typical method used in the agricultural and food sciences to relate spectra to analyte [@roberts_near-infrared_2004]. PLSR calculates components that maximize covariance between predictor and response variables. PLSR uses some number of components, often selected via cross-validation, in order to fit the regression model and is commonly used in spectroscopy because it tends to work well with highly-correlated, noisy spectral data [@wold_pls-regression_2001].\n\nA NIRS-scanned sample of undamaged grain may used for other purposes besides its scan or it may planted as a seed. In wheat and corn, grain protein content has been shown to be heritable [@giancaspro_genetic_2019; @geyer_genetics_2022]. This suggests (at least potentially) that NIRS technology could serve as resource to rapidly identify high CP hemp germplasm, enabling the screening of more germplam as grain, before planting to the field, and thus enabling the more efficient development of high CP hemp grain cultivars.\n\nFor this study, a benchtop NIR spectrometer was used to develop a model to predict CP content based on a data set of hemp grain representing multiple years, locations, and cultivars from grain and dual-purpose hemp types using PLSR.\n\n## MATERIALS AND METHODS\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# bckgrnd <- fread(\"./input_data/simplified_data/background_data_set.csv\") |> setDT()\n\n# spectra <- fread(\"./input_data/simplified_data/train_test_crude_protein.csv\")\n\n # bckgrnd[,in_ny:= ifelse(loc!=\"kentucky\", T, F)]\n \n# bg2 <- bckgrnd[loc!=\"kentucky\"]\n\n# extract indices of non-kentucky\n# bg_indices <- bckgrnd[loc!=\"kentucky\", which = T]\n\n# correct names in bg2--should be h-51, NOT hl-51\n\n# bg2[cultivar==\"hl-51\"]$cultivar <- \"h-51\"\n\n# check to see if i did the calc correctly\n\n# bg2[grepl(\"51\", cultivar),]\n\n #looks good \n# tab <-  table(bckgrnd$in_ny)\n\n\n# now take correct spectra filtering out stuff from KY\n\n# spectra_2 <- spectra[bg_indices]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# should be correct finalized data sets, \n\n# notably, switches sample 2 and 7 around\n\nfull_data <- fread(\"./input_data/final_data_set/full_hemp_data.csv\")\n\ntab <-  table(full_data$in_ny)\n```\n:::\n\n\n### Hemp Grain Sample Background\n\nSpectral data were obtained from whole (unground) hemp grain samples, harvested at maturity, collected from 2017 - 2021 from 18 cultivar trials in New York (NY) (NA samples). Grain samples were obtained by hand sampling or mechanical harvest and were cleaned of chaff and dried at 30 C for six days in a forced-air dryer. In total, 38 cultivars were represented in the data set. Cultivars were grain or dual-purpose types and included both commercially available and experimental material.\n\nAll cultivar trials were planted in randomized complete block design with each cultivar replicated four times. The 2017 data were comprised of samples from the same thirteen cultivars sampled from six NY locations. For those trials, grain was harvested from each plot individually and aggregated by cultivar within each trial. Four subsamples were drawn from each aggregated sample and scanned separately. These spectra were averaged at each 2 nm increment. All remaining samples from 2018-2021 were collected on a per-plot basis. All possible cultivars and possible locations were represented in 2017, but only a selected subset of cultivars and locations were represented in 2018-2021.\n\n### Spectral Data Collection and Preprocessing\n\nA benchtop NIR spectrometer (FOSS/ NIR FOSS/ NIR Systems model 5000) was used to obtain the spectra (FOSS North America, Eden Prairie, MN, USA). Spectra were collected every 2 nm from 1100-2498 nm and the logarithm of reciprocal reflectance was recorded. A 1/4 rectangular sample cup (5.7 cm × 4.6 cm) was used.\n\nWINISI software version 1.02A (Infrasoft International, Port Matilda, PA, USA) was used to average the spectra in 2017, as well as to select samples for laboratory assay. Samples were selected according to their spectral distance from their nearest neighbor within the calibration data set with a cutoff of a distance of 0.6 H, where H is approximately equal to the squared Mahalanobis distance divided by the number of principal components used in the calculation [@garrido-varo_note_2019]. Prior to selection selection, spectra were preprocessed using SNV-detrend with settings 1,4,4,1 for the derivative, gap, smooth, and smooth 2 settings respectively.\n\n### Laboratory Validation\n\nLaboratory assays were performed by Dairy One Forage Laboratory (Ithaca, NY). For those assays, 1mm ground samples were analyzed by combustion using a CN628 or CN928 Carbon/Nitrogen Determinator. Samples from 2017 were aggregated as described above, but the remaining samples were not aggregated.\n\n### Model Development\n\nCalibration and validations sets were created by dividing the laboratory CP values into tertiles according to their percent CP in order to ensure that the range of CP values was present in both calibration and testing sets. Within each tertile, 75% of the samples were randomly assigned to the calibration set and the remaining 25% were assigned to the testing set. For each calibration set, models were developed in the caret package using PLSR. In fitting the model, the number of components was optimized over a grid search from 1-20. Model performance was evaluated with 25 iterations of bootstrapping and minimized root mean squared error (RMSE) in selecting the number of components in the final model .\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npreproc_key <- fread(\"./input_data/final_data_set/preprocessing_key.csv\")\n\npreproc_key[,full_name:= c(\"Raw Spectra\", \"First Derivative\", \"Second Derivative\",\"Savitzky-Golay\", \"Gap-segment Derivative\",\n                           \"Standard Normal Variate\", \"Standard Normal Variate following Savitzky-Golay\", \"Standard Normal Variate-Detrend\", \"Multiplicative Scatter Correction\")]\n```\n:::\n\n\nInitially a number of common spectral preprocessing methods were tested by creating 100 calibration and testing sets, as described above. Spectral data from those data sets were transformed by each of the following methods: 1) first derivative, 2) Savitzky-Golay (SG) using the first derivative, third order polynomial, and a window of size 5, 3) gap-segment derivative using the first derivative, a gap of eleven, and a segment size of 5, 4) standard normal variate (SNV), 5) standard normal variate following Savitzky-Golay (SNV-SG) (same SG parameters as above), 6) SNV-detrend with second order polynomial, and 7) multiplicative scatter correction. As a comparison, models were also developed using untransformed spectra.\n\nFor each of these preprocessing methods, models were fit and predictions were made on the corresponding validation set (since there were 8 preprocessing methods, 8 separate models were fit for each of the 100 sets. The relationship between the predicted and actual values of the testing set were calculated via RMSE, R^2^ and Ratio of Performance to InterQuartile distance (RPIQ), three common model assessment metrics. Larger R^2^ and RPIQ, and smaller RMSE values are superior. Analyses of variance (ANOVA) were performed for each of these metrics in order to compare the preprocessing methods. For each ANOVA, each data set was considered as a subject and different variances were allowed for each preprocessing method.\n\nOnce the most promising preprocessing method was identified, 1000 more data sets were created and analyzed via that method and performance on the testing sets was summarized with RMSE, R^2^, and RPIQ.\n\n### Additional software used\n\n<!-- Additional analyses were performed using R Statistical Software [@r_core_team_r_2024]. Data were tabulated and summarized using the tidyverse and data.table \\[@barrett_datatable_2024; @wickham_welcome_2019\\]. PLSR models were constructed using the pls package and validated using caret \\[@kuhn_building_2008; @liland_pls_2023\\]. -->\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ngrateful::cite_packages(output = \"paragraph\", out.dir = \".\",pkgs = c(\"base\", \"data.table\", \"nlme\", \"tidyverse\", \"caret\", \"pls\", \"prospectr\", \"tidymodels\", \"emmeans\", \"skimr\"))\n```\n\n::: {.cell-output-display}\nWe used R version 4.3.3 [@base] and the following R packages: caret v. 6.0.94 [@caret], data.table v. 1.15.2 [@datatable], emmeans v. 1.10.0 [@emmeans], nlme v. 3.1.163 [@nlme2000; @nlme2023], pls v. 2.8.3 [@pls], prospectr v. 0.2.7 [@prospectr], skimr v. 2.1.5 [@skimr], tidymodels v. 1.1.1 [@tidymodels], tidyverse v. 2.0.0 [@tidyverse].\n:::\n:::\n\n\n## RESULTS AND DISCUSSION\n\n### Laboratory assay CP values\n\nLaboratory assay percent CP values are summarized in the following table. These are similar to the range of CP values observed in the literature, indicating an reasonable basis for a chemometric model. The CP values are left-skewed and two thirds of the samples contained more than 25% CP.\n\n\n::: {#tbl-lab-protein-vals .cell tbl-cap='Summary of Laboratory Assayed CP Values (Percent Dry Matter)'}\n\n```{.r .cell-code .hidden}\nmy_summary <- full_data$crude_protein |> skimr::skim()|> select(c(5:11)) |> \n  mutate_all(round, 1)\nnames(my_summary) <- c(\"mean\", \"sd\", \"minimum\", \"first quartile\", \"median\", \"third quartile\", \"maximum\") |> str_to_title()\n\nknitr::kable(my_summary)\n```\n\n::: {.cell-output-display}\n\n\n| Mean|  Sd| Minimum| First Quartile| Median| Third Quartile| Maximum|\n|----:|---:|-------:|--------------:|------:|--------------:|-------:|\n| 26.1| 2.5|    20.8|           23.9|   26.4|           28.2|    30.8|\n\n\n:::\n:::\n\n\n### Preprocessing methods comparison\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# \nmulti_metric <- metric_set(rmse, rsq, rpiq)\n\n\n# read data back in to work with it\n\nprep_key <- fread(\"./input_data/final_data_set/preprocessing_key.csv\")\n\nsims_key <- fread(\"./input_data/final_data_set/preprocessing_methods_test.csv\")\n\nlong_form <- merge(sims_key, prep_key, all.x = T)\n\n# now pull the metrics\n\n# long_form[, multi_metric(y, value), by = c(\"id\", \"preproc\")]\n\nsummaries <- long_form |> \n  filter(preproc!=\"second_derivative\") |> \n  group_by(id, preproc) |> \n  multi_metric(y, value)\n\n# # comparing methods over a series of metrics...\n# summaries_with_models <- summaries |> \n#   mutate(id = as.character(id)) |> \n#   nest(data = -.metric) |> \n#   mutate(mod = map(data, ~lme4::lmer(.estimate ~ preproc + (1|id), data = .x)),\n#          ems = map(mod, ~emmeans::emmeans(.x, \"preproc\") |> data.frame())\n#          )\n# \n# summaries_with_models_2 <- summaries_with_models |> \n#   select(1, ems) |> \n#   unnest(ems)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# actually, let's summarize via nlme\n# set our varident\nvf2 <- varIdent(form= ~ 1|preproc)\n\n# define custom contrasts\nfirst_part <- rep(1/7,7)\ncontrast_full <- append(first_part, -1, after = 3)\n\n\ncustom <- list(preprocess_vs_raw = contrast_full)\n\nnlme_summaries <- summaries |> \n  mutate(id = as.character(id)) |> \n  nest(data = -.metric) |> \n  mutate(\n    mod_standard = map(data, ~nlme::lme(.estimate ~ preproc, random = ~1|id, data = .x, method =\"ML\")),\n    \n    mod_varident = map(data, ~nlme::lme(.estimate ~ preproc, random = ~1|id, weights = vf2, data = .x, method =\"ML\")),\n    mod_compare = map2(mod_standard, mod_varident, ~anova(.x, .y)),\n         ems = map(mod_varident, ~emmeans::emmeans(.x, \"preproc\") |>multcomp::cld() |>  data.frame()), \n             ems2 = map(mod_varident, ~emmeans::emmeans(.x, \"preproc\")),\n                        contrast = map(ems2, ~emmeans::contrast(.x, custom))\n                                       )\n\n\n\nnlme_summaries_with_models_2 <- nlme_summaries |> \n  select(1, ems) |> \n  unnest(ems)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# add full names\n\nto_table <- nlme_summaries_with_models_2|> \n  left_join(preproc_key) |> \n  select('Preprocessing Method' = full_name, Metric = .metric, Estimate = emmean, SE) |> \n  mutate(Estimate = paste(format(round(Estimate, 2), nsmall = 2), \"±\", format(round(SE, 3), nsmall = 3)))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(preproc)`\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncontrasts <- nlme_summaries |> \n  select(.metric, contrast) |> \n  transmute(.metric, tidy_contrast = map(contrast, tidy)) |> \n  unnest(tidy_contrast)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# lead_lag summaries\nlead_lag <- nlme_summaries_with_models_2 |> select(1:4) |> \n  arrange(.metric, emmean)%>% \n  group_by(.metric) |> \n  mutate(lagged = lag(emmean)) %>% \n  mutate(pct_change = (emmean - lagged) / lagged)|> \n  mutate(lead = lead(emmean)) %>% \n  mutate(pct_change_lead = (emmean - lead) / lead)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# percent change for contrasts\n\nraw_contrast <- nlme_summaries_with_models_2 |> filter(preproc==\"raw\") |> \n  dplyr::select(1:3) |> \n  left_join(contrasts |> select(1,3,estimated_diff = 5)) |> \n  mutate(percent_difference = estimated_diff/(emmean+estimated_diff))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(.metric)`\n```\n\n\n:::\n:::\n\n\nAll preprocessing methods outperformed untransformed spectral data @tbl-preproc. Averaged together, all preprocessed spectra were superior to untransformed spectra, with lower RMSE, and higher R^2^ and RPIQ values (significant at $\\alpha$ level \\<0.001). Preprocessing methods had -11.6 % lower RMSE, and had 3.1% higher R^2^ 7.4% higher RPIQ than unprocessed spectra.\n\nThe SNV-SG method had the lowest RMSE, highest R^2^, and highest RPIQ averaging over all iterations. SNV-SG RMSE averaged 1.4% lower, while R^2^ and RPIQ averaged 0.4% and 2.4% higher respectively than the next best preprocessing method (SG in both cases), but the difference between the best and second best method by metric were only statistically significant at $\\alpha$ \\<0.05 for RPIQ. RPIQ was devised to accurately reflect the spread of data in skewed populations [@bellon-maurel_critical_2010] and thus offers a robust metric for model assessment in this context, where the CP data are skewed. Therefore the superiority of SNV-SG as measured via RPIQ made it the best choice for the final model.\n\n\n::: {#tbl-preproc .cell tbl-cap='Evaluation of Preprocessing Methods by Metric ± Standard Error'}\n\n```{.r .cell-code .hidden}\n# printable table of results\n\nto_table2 <- to_table |> \n  mutate(`Preprocessing Method` = \n           case_match(`Preprocessing Method`,\n             \"Raw Spectra\"~ \"Untransformed Spectra\",\n             .default=`Preprocessing Method`\n           )) |> \n  select(1:3) |> \n  pivot_wider(names_from = Metric, values_from = Estimate) |> \n  arrange(rmse) |> \n  rename(RMSE = rmse, RPIQ = rpiq ) \n# names(to_table2)[3] <- \"$^{2}$\"\nto_table2|> \n  knitr::kable(col.names = c(\"Preprocessing Method\", \"RMSE\", \"$R^{2}$\", \"RPIQ\"))\n```\n\n::: {.cell-output-display}\n\n\n|Preprocessing Method                             |RMSE         |$R^{2}$      |RPIQ         |\n|:------------------------------------------------|:------------|:------------|:------------|\n|Standard Normal Variate following Savitzky-Golay |1.02 ± 0.012 |0.84 ± 0.004 |3.97 ± 0.076 |\n|Savitzky-Golay                                   |1.03 ± 0.012 |0.83 ± 0.004 |3.88 ± 0.072 |\n|First Derivative                                 |1.07 ± 0.013 |0.82 ± 0.004 |3.77 ± 0.075 |\n|Standard Normal Variate                          |1.12 ± 0.016 |0.80 ± 0.005 |3.61 ± 0.081 |\n|Gap-segment Derivative                           |1.12 ± 0.018 |0.81 ± 0.006 |3.60 ± 0.086 |\n|Standard Normal Variate-Detrend                  |1.13 ± 0.015 |0.80 ± 0.005 |3.55 ± 0.079 |\n|Multiplicative Scatter Correction                |1.17 ± 0.016 |0.79 ± 0.006 |3.47 ± 0.080 |\n|Untransformed Spectra                            |1.22 ± 0.044 |0.79 ± 0.009 |3.42 ± 0.105 |\n\n\n:::\n:::\n\n\nThese results are not surprising. SNV and SNV-detrend both correct light scatter, which is often a function of differences in particle size and sample packing density, although SNV-detrend is often used for densely-packed, powdered samples [@barnes_standard_1989]. Here, hemp grain was neither powdered nor densely packed SG is a smoothing filter that regresses on the signal over a series of windows, removing noise while preserving the signal's shape and features.[@li_quantitative_2020; @luo_properties_2005]. Derivatives remove noise, but not necessarily light scatte\n\n**cite:** Barnes RJ, Dhanoa MS, Lister SJ. 1989. Standard normal variate transformation and de-trending of near-infrared diffuse reflectance spectra. Applied spectroscopy, 43(5): 772-777.\n\nThe preprocessing methods examined represent a portion of those available. As well, preprocessing methods tend to have a number of user-adjustable parameters whose various permutations were not tested. This subset of preprocessing methods and parameters nonetheless contained substantial variations in model quality, demonstrating the importance of the selection of an appropriate preprocessing method.\n\n### Final model development and summary\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel_n_comp_statistics <- fread(\"./input_data/final_data_set/final_model_n_component_stats.csv\")\n\n# define a function to calculate percent difference\npct_lower <- function(x){\n  my_lag = data.table::shift(x, type = \"lag\")\n  round((x - my_lag)/my_lag*100,2)\n}\n\navg_change <- model_n_comp_statistics[,lapply(.SD, mean),.SDcols = 3:8, by= ncomp]\n\nchange_per_pc <- avg_change[, lapply(.SD, pct_lower), .SDcols = 2:7]\n```\n:::\n\n\nThe model improved most rapidly as the number of principal components increased from 1 to 7, with the inclusion of each additional PC being associated with a decrease in RMSE of 5-12% . From 8 to 12 PCs, model performance continued to improve, although gains were more modest (decrease in RMSE of 0.7-3%). With 13 or more PCs, performance gains were minimal and the relative ranks of the models tended to be stable @fig-model-calibration.\n\n\n::: {#cell-fig-model-calibration .cell}\n\n```{.r .cell-code .hidden}\nmodel_n_comp_statistics |> \n  ggplot(aes(as.factor(ncomp), RMSE)) + \n  geom_line(aes(group = id), alpha = 0.03) + \n  theme_classic() + \n  xlab(\"Crude Protein Model Number of Principal Components\") + \n  ylab(\"Crude Protein Model Root Mean Squared Error\")\n```\n\n::: {.cell-output-display}\n![Decreasing RMSE with increasing number of PCs](index_files/figure-html/fig-model-calibration-1.png){#fig-model-calibration width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel_final_predictions <- fread(\"./input_data/final_data_set/final_model_predictions.csv\")\n\nfinal_model_table <- model_final_predictions |> \n  group_by(id) |> \n  multi_metric(crude_protein, predicted_crude_protein) |> setDT()\n```\n:::\n\n\nFinal model performance was similar, but not identical to, that obtained during the initial comparison of preprocessing methods. The final models' mean RMSE was 1.03, R^2^ was 0.83, and RPIQ was 3.89 (all calculated on the test sets). Despite the generally good model performance, a subset of poor models can be seen. For example, @fig-final-metric-boxplot shows twenty-one models with R^2^ below 0.7. **more comment on poor models?**\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nskim_metrics <- final_model_table |> \n  group_by(.metric) |> \n  skimr::skim()\n```\n:::\n\n::: {#cell-fig-final-metric-boxplot .cell}\n\n```{.r .cell-code .hidden}\n# setnames(model_final_predictions, \"V1\", \"crude_protein\")\n\n\n\nfinal_model_table |>\n  mutate(metric2 = toupper(.metric)) |> \n  ggplot(aes(x = .metric, y = .estimate)) + \n  theme_classic() + geom_boxplot() + \n  facet_wrap(vars(metric2), scales = \"free\") +\n  xlab(\"Metric\") + ylab(\"Estimate\")+\n  theme(\n    axis.title.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank())\n```\n\n::: {.cell-output-display}\n![Final model validation set performance (1000 iterations)](index_files/figure-html/fig-final-metric-boxplot-1.png){#fig-final-metric-boxplot width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# add difference calculation between predicted and observed...\nmodel_final_predictions[,difference := predicted_crude_protein - crude_protein]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# my_cut <- cut(spectra_2$crude_protein, 3)\n# cut_dt <- data.table(ith_in_data_set = 1:149, cutpoints = my_cut)\n\n\n# revised_model_cutpoints\ncutpoints2 <- model_final_predictions |> \n  distinct(ith_in_data_set, crude_protein) |> \n  mutate(cutpoints = cut(crude_protein, 3)) |> \n  arrange(crude_protein) |> \n  mutate(plot_order = 1:n())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata_sum_by_sample <- model_final_predictions[,lapply(.SD, mean), .SDcols = c(\"crude_protein\", \"difference\"), by = \"ith_in_data_set\"]\nsetorder(data_sum_by_sample, crude_protein)\ntemp_dat <- copy(data_sum_by_sample)\n# create temporary ith\ntemp_dat[,tmp_ith:= 1:.N]\nmin_val <- min(temp_dat$crude_protein)\n# center this\ntemp_dat[,adj_cp:= crude_protein - min_val]\n\nlm_mod <- lm(difference~adj_cp, data = temp_dat) \nsummary(lm_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = difference ~ adj_cp, data = temp_dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.51794 -0.58132  0.06936  0.50754  2.74745 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.80412    0.17827   4.511 1.31e-05 ***\nadj_cp      -0.15334    0.03051  -5.026 1.44e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9138 on 147 degrees of freedom\nMultiple R-squared:  0.1466,\tAdjusted R-squared:  0.1408 \nF-statistic: 25.26 on 1 and 147 DF,  p-value: 1.438e-06\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ncoefs <- coef(lm_mod)\n\npreds <- predict(lm_mod, temp_dat)\nds_preds <- temp_dat[,c(\"ith_in_data_set\")] |> cbind(preds)\n\nds_cutpoints <- merge(ds_preds, cutpoints2)\nsetorder(ds_cutpoints, plot_order)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsd_mod <- model_final_predictions[,list(sd_diff = sd(difference), crude_protein = mean(crude_protein)), by = \"ith_in_data_set\"]\nsetorder(sd_mod, crude_protein)\ntemp_dat_sd <- copy(sd_mod)\n# create temporary ith\ntemp_dat_sd[,tmp_ith:= 1:.N]\nmin_val_sd <- min(temp_dat_sd$crude_protein)\n# center this\ntemp_dat_sd[,adj_cp:= crude_protein - min_val]\n\nlm_mod_sd <- lm(sd_diff~adj_cp, data = temp_dat_sd) \n```\n:::\n\n\nFinally, the pattern of errors was examined on a per-sample basis. @fig-validation_set_performance\n\n\n::: {#cell-fig-validation_set_performance .cell}\n\n```{.r .cell-code .hidden}\n# \n\nmodel_final_predictions |> \n  left_join(cutpoints2) |> \n  arrange(plot_order) |> \n  ggplot(aes(plot_order, crude_protein))+\n  geom_point(aes(plot_order, difference), alpha = 0.05, shape = 2) +\n  geom_hline(yintercept = 0, linewidth = 2, lty = 2) +\n  geom_point(data = ds_cutpoints, aes(plot_order, preds), shape = 3)+\n  facet_wrap( ~cutpoints, scales = \"free_x\",\n              labeller = as_labeller(c(\"(20.8,24.1]\" = \"Low CP (20.8 - 24.1%)\",\n                                       \"(24.1,27.5]\"= \"Medium CP (24.2 - 27.5%)\",\n                                       \"(27.5,30.8]\" =\"High CP (27.6-30.8%)\")))+ \n  ylab(\"Crude Protein Predicted Percent Difference\\nfrom Assayed Value\")+\n  theme_classic()+\n  theme(\n    axis.title.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank()) \n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(crude_protein, ith_in_data_set)`\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Test set prediction errors on a per-sample basis. Actual sample value set to 0, and samples ranked from least to greatest actual % CP value](index_files/figure-html/fig-validation_set_performance-1.png){#fig-validation_set_performance width=672}\n:::\n:::\n\n\n\\\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncts <- ds_cutpoints[,mean(preds), by=cutpoints]\n```\n:::\n\n\nTo assess the patterns of errors within the models, a linear model was fit considering the mean estimated error for each sample considering all models where that sample was in the test set when compared to the sample's actual value. The models overestimated %CP by approximately 0.5 % in the lowest tertile and underestimated %CP by -0.01 % and -0.41 % in the middle and highest tertile, respectively\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# look\n# read in stuff for supplemental table first\nsupp_tab <- fread(\"./input_data/final_data_set/cultivar_table_clean.csv\")\n\n# read in correct location key\nlocs2 <- fread(\"./input_data/final_data_set/corrected_location_key.csv\")\n\n# sort highest and lowest samples...\ntd2 <- temp_dat[order(abs(difference))]\n\n# sort highest and lowest\ntd3 <- td2[!c(16:134),][,grouping:=rep(c(\"best_predicted_10pct\", \"worst_predicted_10_pct\"), each = 15)]\n\n# incorporate background\n\ntd4_bckgrd <- merge(td3, full_data[,1:7], all.x = T)\n\nmerge( td4_bckgrd,locs2, by.y =\"loc\", by.x= 'loc', all.x = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <loc>\n          loc ith_in_data_set crude_protein   difference tmp_ith adj_cp\n       <char>           <int>         <num>        <num>   <int>  <num>\n 1:     cnoll               4          27.1 -1.826000348      90    6.3\n 2:      free              91          23.1 -1.608410140      24    2.3\n 3:      free             100          27.5  0.008386084     100    6.7\n 4:      free             103          26.0 -0.095290561      64    5.2\n 5:     freev              66          28.3  0.156805468     117    7.5\n 6:     freev              69          28.7  0.115415937     128    7.9\n 7:     freev              70          27.3  0.123941888      93    6.5\n 8:    ithaca             123          25.9  0.137420230      60    5.1\n 9:    ithaca             124          23.2  2.325322409      27    2.4\n10:    ithaca             125          23.2  2.582685059      25    2.4\n11:    ithaca             140          23.5  1.597167816      30    2.7\n12:    ithaca             146          28.0 -1.965391942     110    7.2\n13:    ithaca             148          26.4  0.145123025      76    5.6\n14:       mcg              92          22.7 -0.110406545      20    1.9\n15:       mcg              94          28.1 -0.067559276     111    7.3\n16:       mcg             121          28.3 -2.434565554     115    7.5\n17:      mg4e              28          25.4  0.034158139      53    4.6\n18:      mg4e              39          26.1 -0.016921027      66    5.3\n19:      mg4l              41          26.4  0.118021909      74    5.6\n20: rn041_gen             108          27.0  2.600884960      86    6.2\n21: rn041_gen             109          23.7 -1.980462540      33    2.9\n22: rn041_gen             110          29.0 -2.495337360     135    8.2\n23: rn041_gen             111          29.6 -1.777305991     140    8.8\n24: rn041_gen             113          29.5  0.011781362     139    8.7\n25: rn041_gen             114          27.7  2.115039075     107    6.9\n26:     rnooa              14          29.1 -0.003578789     137    8.3\n27:     rnooa              18          23.1  2.020690041      22    2.3\n28:     rnooa              19          25.3 -0.110141285      52    4.5\n29:     rnooa              25          26.6 -2.603177621      78    5.8\n30:     rnooa              26          28.3 -2.034162792     114    7.5\n          loc ith_in_data_set crude_protein   difference tmp_ith adj_cp\n                  grouping temp_id harv_year         cultivar         type\n                    <char>   <int>     <int>           <char>       <char>\n 1: worst_predicted_10_pct      32      2017            cfx-1             \n 2: worst_predicted_10_pct     111      2018           grandi        grain\n 3:   best_predicted_10pct     128      2019            canda        grain\n 4:   best_predicted_10pct     131      2019        nwg-elite         dual\n 5:   best_predicted_10pct      94      2017           picolo             \n 6:   best_predicted_10pct      97      2017        futura 75             \n 7:   best_predicted_10pct      98      2017            cfx-1             \n 8:   best_predicted_10pct     155      2020         nwg-2730   multistate\n 9: worst_predicted_10_pct     152      2020        futura 75 dual_replant\n10: worst_predicted_10_pct     156      2020    bialobrzeskie   multistate\n11: worst_predicted_10_pct       9      2021         logan c2         exp.\n12: worst_predicted_10_pct       5      2021            crs-1   grain_dual\n13:   best_predicted_10pct      10      2021  logan x anka c2         exp.\n14:   best_predicted_10pct     115      2018 nebraska (feral)         dual\n15:   best_predicted_10pct     113      2018           picolo        grain\n16: worst_predicted_10_pct     149      2019             h-51   multistate\n17:   best_predicted_10pct      56      2017            cfx-2             \n18:   best_predicted_10pct      67      2017        futura 75             \n19:   best_predicted_10pct      69      2017             anka             \n20: worst_predicted_10_pct     136      2019        earlina 8        grain\n21: worst_predicted_10_pct     137      2019           katani        grain\n22: worst_predicted_10_pct     138      2019             joey        grain\n23: worst_predicted_10_pct     139      2019        futura 75         dual\n24:   best_predicted_10pct     141      2019             h-51         dual\n25: worst_predicted_10_pct     142      2019           hliana         dual\n26:   best_predicted_10pct      42      2017            tygra             \n27: worst_predicted_10_pct      46      2017           katani             \n28:   best_predicted_10pct      47      2017            cfx-2             \n29: worst_predicted_10_pct      53      2017            cfx-1             \n30: worst_predicted_10_pct      54      2017            wojko             \n                  grouping temp_id harv_year         cultivar         type\n     in_ny      loc2\n    <lgcl>    <char>\n 1:   TRUE    geneva\n 2:   TRUE freeville\n 3:   TRUE freeville\n 4:   TRUE freeville\n 5:   TRUE freeville\n 6:   TRUE freeville\n 7:   TRUE freeville\n 8:   TRUE    ithaca\n 9:   TRUE    ithaca\n10:   TRUE    ithaca\n11:   TRUE    ithaca\n12:   TRUE    ithaca\n13:   TRUE    ithaca\n14:   TRUE    ithaca\n15:   TRUE    ithaca\n16:   TRUE    ithaca\n17:   TRUE    ithaca\n18:   TRUE    ithaca\n19:   TRUE    ithaca\n20:   TRUE    geneva\n21:   TRUE    geneva\n22:   TRUE    geneva\n23:   TRUE    geneva\n24:   TRUE    geneva\n25:   TRUE    geneva\n26:   TRUE    geneva\n27:   TRUE    geneva\n28:   TRUE    geneva\n29:   TRUE    geneva\n30:   TRUE    geneva\n     in_ny      loc2\n```\n\n\n:::\n:::\n\n\nThis study is limited in that it represents the creation of one model based upon spectra collected from one machine. NIRS calibrations can be unique to a particular machine, even if the machines compared are of the same model [@reeves_potential_2012]. As well, the calibration and validation sets are relatively small.\n\nThis research showed the promise of the use of NIRS in order to make predictions concerning %CP in hemp grain using PLS. Promising preprocessing methods were identified and a model was validated. Further research could refine a CP model by including more samples, identifying promising spectral regions, or by examining other predictive methods.\n\n## ACKNOWLEDGMENTS\n\n## SUPPLEMENTAL MATERIAL\n\n\n::: {#tbl-hemp_provenance .cell tbl-cap='Tally of hemp cultivars and locations. Private cultivars are labeled \"cultivar1\", \"cultivar2\", etc.'}\n\n```{.r .cell-code .hidden}\noptions(knitr.kable.NA = '')\nknitr::kable(supp_tab)\n```\n\n::: {.cell-output-display}\n\n\n|cultivar2        | chazy| freeville| geneva| ithaca| willsboro| Total|\n|:----------------|-----:|---------:|------:|------:|---------:|-----:|\n|altair           |      |          |       |      1|          |     1|\n|anka             |      |         1|      3|      5|         2|    11|\n|bialobrzeskie    |      |         1|      3|      4|         1|     9|\n|canda            |      |         1|      1|      1|          |     3|\n|cfx-1            |      |         1|      2|      5|          |     8|\n|cfx-2            |      |         1|      2|      4|          |     7|\n|crs-1            |     1|         1|      2|      5|          |     9|\n|cultivar1        |      |         1|       |       |          |     1|\n|cultivar2        |      |          |       |      1|          |     1|\n|cultivar3        |      |          |       |      1|          |     1|\n|cultivar4        |      |          |       |      1|          |     1|\n|earlina 8        |      |          |      1|       |          |     1|\n|experimental1    |      |          |       |      1|          |     1|\n|experimental2    |      |          |       |      1|          |     1|\n|felina 32        |      |         1|      2|      3|          |     6|\n|futura 75        |      |         1|      3|      4|          |     8|\n|grandi           |      |         3|      3|      4|          |    10|\n|h-51             |      |          |      1|      2|          |     3|\n|han-fn-h         |      |          |       |      1|          |     1|\n|han-nw           |      |          |       |      1|          |     1|\n|helena           |      |         1|       |       |          |     1|\n|henola           |      |          |       |      2|          |     2|\n|hlesia           |      |          |       |      3|          |     3|\n|hliana           |      |          |      1|      1|          |     2|\n|joey             |      |         1|      1|      1|          |     3|\n|katani           |      |         2|      3|      4|          |     9|\n|nebraska (feral) |     1|          |       |      1|          |     2|\n|pewter river     |      |         1|       |       |          |     1|\n|picolo           |      |         1|      2|      5|          |     8|\n|portugal         |      |          |      1|       |          |     1|\n|rocky hemp       |      |          |      1|       |          |     1|\n|sterling gold    |      |          |      1|       |          |     1|\n|swift            |     1|         1|       |      1|          |     3|\n|tygra            |      |         1|      3|      4|          |     8|\n|uso-31           |     2|         1|      2|      4|          |     9|\n|wojko            |      |         1|      3|      4|          |     8|\n|x-59             |      |         2|       |      1|          |     3|\n|Total            |     5|        24|     41|     76|         3|   149|\n\n\n:::\n:::\n\n\n## OPTIONAL SECTIONS\n\n## REFERENCES\n\n## FIGURES AND TABLES\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\neruptions <- c(1492, 1585, 1646, 1677, 1712, 1949, 1971, 2021)\nn_eruptions <- length(eruptions)\n```\n:::\n\n::: {#cell-fig-timeline .cell}\n\n```{.r .cell-code .hidden}\npar(mar = c(3, 1, 1, 1) + 0.1)\nplot(eruptions, rep(0, n_eruptions), \n  pch = \"|\", axes = FALSE)\naxis(1)\nbox()\n```\n\n::: {.cell-output-display}\n![Timeline of recent earthquakes on La Palma](index_files/figure-html/fig-timeline-1.png){#fig-timeline fig-alt='An event plot of the years of the last 8 eruptions on La Palma.' width=576}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\navg_years_between_eruptions <- mean(diff(eruptions[-n_eruptions]))\navg_years_between_eruptions\n```\n\n::: {.cell-output .cell-output-stdout .hidden}\n\n```\n[1] 79.83333\n```\n\n\n:::\n:::\n\n\nBased on data up to and including 1971, eruptions on La Palma happen every 79.8 years on average.\n\nStudies of the magma systems feeding the volcano, such as @marrero2019, have proposed that there are two main magma reservoirs feeding the Cumbre Vieja volcano; one in the mantle (30-40km depth) which charges and in turn feeds a shallower crustal reservoir (10-20km depth).\n\nEight eruptions have been recorded since the late 1400s (@fig-timeline).\n\nData and methods are discussed in @sec-data-methods.\n\nLet $x$ denote the number of eruptions in a year. Then, $x$ can be modeled by a Poisson distribution\n\n$$\np(x) = \\frac{e^{-\\lambda} \\lambda^{x}}{x !}\n$$ {#eq-poisson}\n\nwhere $\\lambda$ is the rate of eruptions per year. Using @eq-poisson, the probability of an eruption in the next $t$ years can be calculated.\n\n| Name                | Year |\n|---------------------|------|\n| Current             | 2021 |\n| Teneguía            | 1971 |\n| Nambroque           | 1949 |\n| El Charco           | 1712 |\n| Volcán San Antonio  | 1677 |\n| Volcán San Martin   | 1646 |\n| Tajuya near El Paso | 1585 |\n| Montaña Quemada     | 1492 |\n\n: Recent historic eruptions on La Palma {#tbl-history}\n\n@tbl-history summarises the eruptions recorded since the colonization of the islands by Europeans in the late 1400s.\n\n![Map of La Palma](images/la-palma-map.png){#fig-map}\n\nLa Palma is one of the west most islands in the Volcanic Archipelago of the Canary Islands (@fig-map).\n\n\n{{< embed notebooks/explore-earthquakes.qmd#fig-spatial-plot >}}\n\n\n\n@fig-spatial-plot shows the location of recent Earthquakes on La Palma.\n\n## Data & Methods {#sec-data-methods}\n\n## Conclusion\n\n## References {.unnumbered}\n\n::: {#refs}\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}