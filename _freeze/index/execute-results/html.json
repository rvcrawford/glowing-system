{
  "hash": "2dda51ceda42cc9b2fe5cf87e1be0e14",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Near Infrared Spectroscopy Predicts Percentage Crude Protein in Hemp Grain\nexecute:\n  freeze: auto\n  echo: false\nauthor:\n  - name: Ryan V. Crawford\n    orcid: 0009-0006-3052-3269\n    corresponding: true\n    email: rvc3@cornell.edu\n    # roles:\n    #   - Investigation\n    #   - Project administration\n    #   - Software\n    #   - Visualization\n    affiliations:\n      - name: Cornell University\n        address: 126 Medicago Drive\n        city: Ithaca\n        state: NY\n        postal-code: 14853\n  - name: Jamie L. Crawford\n    orcid: 0009-0002-2523-3479\n    corresponding: false\n    # roles:\n    #   - Investigation\n    #   - Project administration\n    #   - Software\n    #   - Visualization\n    affiliations:\n      - name: Cornell University\n        address: 126 Medicago Drive\n        city: Ithaca\n        state: NY\n        postal-code: 14853\n  - name: Julie L. Hansen\n    orcid: 0000-0001-7247-9186\n    corresponding: false\n    # roles:\n    #   - Investigation\n    #   - Project administration\n    #   - Software\n    #   - Visualization\n    affiliations:\n      - name: Cornell University\n        address: 126 Medicago Drive\n        city: Ithaca\n        state: NY\n        postal-code: 14853\n  - name: Lawrence B. Smart\n    orcid: 0000-0002-7812-7736\n    corresponding: false\n    roles: []\n    affiliations:\n      - name: Cornell AgriTech\n        address: 102 Hedrick Hall\n        city: Geneva\n        state: NY\n        postal-code: 14456\n  - name: Virginia M. Moore\n    orcid: 0000-0001-7888-3366\n    corresponding: false\n    roles: []\n    affiliations:\n      - name: Cornell University\n        address: 162 Emerson Hall\n        city: Ithaca\n        state: NY\n        postal-code: 14853    \nkeywords:\n  - Hemp\n  - Grain\n  - Spectroscopy\nabstract: |\n  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nplain-language-summary: |\n  A model was developed to predict percent crude protein in hemp grain using near infrared spectroscopy.\nkey-points:\n  - A model was developed to predict percent crude protein in hemp grain using near infrared spectroscopy.\ndate: last-modified\nbibliography: \n  - references.bib\n  - grateful-refs.bib\n\ncsl: apa.csl\n# citation:\n#   container-title: Earth and Space Science\nnumber-sections: true\n---\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(data.table)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(prospectr)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[34mprospectr version 0.2.7 -- cakes\u001b[39m\n\u001b[34mcheck the package repository at: https://github.com/l-ramirez-lopez/prospectr\u001b[39m\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(pls)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'pls'\n\nThe following object is masked from 'package:prospectr':\n\n    msc\n\nThe following object is masked from 'package:caret':\n\n    R2\n\nThe following object is masked from 'package:stats':\n\n    loadings\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5      ✔ rsample      1.2.0 \n✔ dials        1.2.1      ✔ tune         1.1.2 \n✔ infer        1.0.6      ✔ workflows    1.1.4 \n✔ modeldata    1.3.0      ✔ workflowsets 1.0.1 \n✔ parsnip      1.2.0      ✔ yardstick    1.3.0 \n✔ recipes      1.0.10     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ data.table::between()    masks dplyr::between()\n✖ scales::discard()        masks purrr::discard()\n✖ dplyr::filter()          masks stats::filter()\n✖ data.table::first()      masks dplyr::first()\n✖ recipes::fixed()         masks stringr::fixed()\n✖ dplyr::lag()             masks stats::lag()\n✖ data.table::last()       masks dplyr::last()\n✖ caret::lift()            masks purrr::lift()\n✖ yardstick::precision()   masks caret::precision()\n✖ yardstick::recall()      masks caret::recall()\n✖ yardstick::sensitivity() masks caret::sensitivity()\n✖ yardstick::spec()        masks readr::spec()\n✖ yardstick::specificity() masks caret::specificity()\n✖ recipes::step()          masks stats::step()\n✖ data.table::transpose()  masks purrr::transpose()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(nlme)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'nlme'\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(kableExtra)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n```\n\n\n:::\n:::\n\n\n**draft incorporates changes from Ginny and Julie**\n\n## INTRODUCTION\n\nHemp (Cannabis sativa L.) is an annual crop with potential uses as a source of food or feed, derived from the grain, and fiber (bast or hurd), derived from the stalk. Hemp cultivars are commonly grown for one or both purposes and a cultivar may be called a grain, fiber, or dual-purpose type. Because of protein's nutritional importance, the protein content of a grain crop is a prime consideration for researchers, producers, and consumers. Whole hemp grain typically contains approximately 200-300 g kg^−1^ protein [@ely_industrial_2022; @barta_proteomic_2024; @callaway_hempseed_2004]. Crude protein is often used as a proxy for the direct measurement of protein concentration and consists of the multiplication of nitrogen concentration by a conversion factor, often 6.25 [@hayes_measuring_2020].\n\nNear-infrared (NIR) spectroscopy (NIRS) technology is rapid, non-destructive, and inexpensive. It consists of the measurement of near-infrared radiation reflected and absorbed from a sample (the spectra) and the relation of the spectra to laboratory values, typically obtained using wet chemistry assays, for components such as moisture, protein, fat, or fiber [@roberts_near-infrared_2004]. NIRS technology has been used since the 1970's to assess forage percentageCP [@reeves_potential_2012; @williams_application_1975]. A NIRS calibration set often consists of samples from one species grown in many environments encompassing the range of expected values from the analyte or analytes [@chadalavada_nir_2022]. Partial least squares regression (PLSR) is a typical method used in the agricultural and food sciences to relate spectra to analyte [@roberts_near-infrared_2004]. Partial least squares regression calculates components that maximize covariance between predictor and response variables. Partial least squares regression uses some number of components, often selected via cross-validation, to fit the regression model and is commonly used in spectroscopy because it tends to work well with highly correlated, noisy spectral data [@wold_pls-regression_2001].\n\nA NIRS-scanned sample of whole grain may be used for other purposes besides the scan, including planting as a seed. In wheat and corn, grain protein content has been shown to be heritable [@giancaspro_genetic_2019; @geyer_genetics_2022]. This suggests that NIRS technology could serve as a resource to rapidly identify high percent CP hemp germplasm, enabling the screening of germplasm as seed, before planting to the field, and facilitating the efficient development of high percent CP hemp populations.\n\nFor this study, a benchtop NIR spectrometer was used to develop a model to predict percent CP content based on a data set of hemp grain representing multiple years, locations, and cultivars from grain and dual-purpose hemp types using PLSR.\n\n## MATERIALS AND METHODS\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# bckgrnd <- fread(\"./input_data/simplified_data/background_data_set.csv\") |> setDT()\n\n# spectra <- fread(\"./input_data/simplified_data/train_test_crude_protein.csv\")\n\n # bckgrnd[,in_ny:= ifelse(loc!=\"kentucky\", T, F)]\n \n# bg2 <- bckgrnd[loc!=\"kentucky\"]\n\n# extract indices of non-kentucky\n# bg_indices <- bckgrnd[loc!=\"kentucky\", which = T]\n\n# correct names in bg2--should be h-51, NOT hl-51\n\n# bg2[cultivar==\"hl-51\"]$cultivar <- \"h-51\"\n\n# check to see if i did the calc correctly\n\n# bg2[grepl(\"51\", cultivar),]\n\n #looks good \n# tab <-  table(bckgrnd$in_ny)\n\n\n# now take correct spectra filtering out stuff from KY\n\n# spectra_2 <- spectra[bg_indices]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# should be correct finalized data sets, \n\n# notably, switches sample 2 and 7 around\n\nfull_data <- fread(\"./input_data/final_data_set/full_hemp_data.csv\")\n\ntab <-  table(full_data$in_ny)\n```\n:::\n\n\n### Hemp Grain Sample Background\n\nSpectral data were obtained from whole (unground) hemp grain samples, harvested at maturity, collected from 2017 - 2021 from 18 cultivar trials in New York (NY) (149 samples). Grain samples were obtained by hand sampling or mechanical harvest and were cleaned of chaff and dried at 30 C for six days in a forced-air dryer. All CP values were expressed as percent dry matter. In total, 149 samples from 38 cultivars were represented in the data set. Cultivars were grain or dual-purpose types and included both commercially available and experimental material. Seventy-eight samples were scanned and assayed in 2017, 19 in 2018, 24 in 2019, and 28 in 2021. More information about hemp cultivars and locations is available in @tbl-hemp_provenance.\n\nAll cultivar trials were planted in randomized complete block design with each cultivar replicated four times. The 2017 data were comprised of samples from the same thirteen cultivars sampled from six NY locations. For those trials, grain was harvested from each plot individually and aggregated by cultivar within each trial. Four subsamples were drawn from each aggregated sample and scanned separately. These spectra were averaged at each 2 nm increment. All remaining samples from 2018-2021 were collected on a per-plot basis. All cultivars and locations were represented in 2017, but only a selected subset of cultivar-location combinations were represented in 2018-2021 because not all cultivars were planted everywhere and only a portion of these cultivar-location combinations were sampled, scanned, and assayed due to logistical constraints.\n\n### Spectral Data Collection and Preprocessing\n\nA benchtop NIR spectrometer (FOSS/ NIR FOSS/ NIR Systems model 5000) was used to obtain the spectra (FOSS North America, Eden Prairie, MN, USA). Spectra were collected every 2 nm from 1100-2498 nm and the logarithm of reciprocal reflectance was recorded. A 1/4 rectangular sample cup (5.7 cm × 4.6 cm) was used to scan the samples.\n\nWINISI software version 1.02A (Infrasoft International, Port Matilda, PA, USA) was used to calculate the mean spectra in 2017 and to select samples for laboratory assay in all years. Samples were selected according to their spectral distance from their nearest neighbor within the calibration data set with a cutoff of a distance of 0.6 H, where H is approximately equal to the squared Mahalanobis distance divided by the number of principal components used in the calculation [@garrido-varo_note_2019]. Prior to selection, spectra were preprocessed using SNV-detrend with settings 1,4,4,1 for the derivative, gap, smooth, and smooth 2 settings respectively.\n\n### Laboratory Validation\n\nLaboratory assays were performed by Dairy One Forage Laboratory (Ithaca, NY). For those assays, 1 mm ground samples were analyzed by combustion using a CN628 or CN928 Carbon/Nitrogen Determinator. Samples from 2017 were aggregated as described above, but the remaining samples were not aggregated.\n\n### R software and packages used\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ngrateful::cite_packages(output = \"paragraph\", out.dir = \".\",pkgs = c(\"base\", \"data.table\", \"nlme\", \"tidyverse\", \"caret\", \"pls\", \"prospectr\", \"tidymodels\", \"emmeans\", \"skimr\"))\n```\n\n::: {.cell-output-display}\nWe used R version 4.3.3 [@base] and the following R packages: caret v. 6.0.94 [@caret], data.table v. 1.15.2 [@datatable], emmeans v. 1.10.0 [@emmeans], nlme v. 3.1.163 [@nlme2000; @nlme2023], pls v. 2.8.3 [@pls], prospectr v. 0.2.7 [@prospectr], skimr v. 2.1.5 [@skimr], tidymodels v. 1.1.1 [@tidymodels], tidyverse v. 2.0.0 [@tidyverse].\n:::\n:::\n\n\n### Model Development\n\nTraining and testing sets were created by dividing the laboratory percentage CP values into tertiles according to their percentage CP to ensure that the range of percentage CP values was present in both calibration and testing sets. Within each tertile, 75% of the samples were randomly assigned to the training set and the remaining 25% were assigned to the testing set. For each training set, models were developed in the caret package using PLSR. In fitting the model, the number of components was optimized over a grid search from 1-20. Model performance was evaluated with 25 iterations of bootstrapping and minimized root mean squared error (RMSE) in selecting the number of components in the final model.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npreproc_key <- fread(\"./input_data/final_data_set/preprocessing_key.csv\")\n\npreproc_key[,full_name:= c(\"Raw Spectra\", \"First Derivative\", \"Second Derivative\",\"Savitzky-Golay\", \"Gap-segment Derivative\",\n                           \"Standard Normal Variate\", \"Standard Normal Variate following Savitzky-Golay\", \"Standard Normal Variate-Detrend\", \"Multiplicative Scatter Correction\")]\n```\n:::\n\n\nInitially a number of common spectral preprocessing methods were tested by creating 100 training and testing sets, as described above. Spectral data were transformed by each of the following methods: 1) first derivative, 2) Savitzky-Golay (SG) using the first derivative, third order polynomial, and a window of size 5, 3) gap-segment derivative using the first derivative, a gap of 11, and a segment size of 5, 4) standard normal variate (SNV), 5) standard normal variate following Savitzky-Golay (SNV-SG) using the same SG parameters as above, 6) SNV-detrend with second order polynomial, and 7) multiplicative scatter correction. For comparison, models were also developed using untransformed spectra.\n\nFor each of these preprocessing methods, models were fit and predictions were made on the corresponding testing set. Since there were 7 preprocessing methods as well as untransformed spectra, 8 separate models were fit for each of the 100 sets. The relationship between the predicted and actual values of the test set were calculated via RMSE, coefficient of determination (R^2^), relative predicted deviation (RPD), and Ratio of Performance to InterQuartile distance (RPIQ), four common model assessment metrics. Larger R^2^, RPD and RPIQ values and smaller RMSE values are best. The answer to the question of exactly which values constitute a \"good\" model varies depending upon the reference consulted, but for simplicity's sake researchers desired a model with R^2^ \\> 0.80, an RPD greater than 2.5 and ideally greater than 3 (\"good\" to \"excellent\" quantitative prediction), and an RPIQ greater than 2.3 but ideally greater than 4.1 prediction on the testing set [@rawal_visible_2024; @luce_prediction_2017; @chadalavada_nir_2022].\n\nAnalyses of variance (ANOVA) were performed for each of these metrics in order to compare preprocessing methods. For each ANOVA, each data set was considered as a subject and different variances were allowed for each preprocessing method. Once the most promising preprocessing method was identified, 1000 more training and testing sets were created, and models were developed with that method. Performance on the testing sets was summarized with RMSE, R^2^, RPD, and RPIQ. The pattern of errors, expressed as the difference between the actual and predicted values for a given sample, was examined.\n\n## RESULTS AND DISCUSSION\n\n### Laboratory assay percentageCP values\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nskewness <- function(x) {\n\n    n <- length(x)\n\n    mean_x <- mean(x)\n    sd_x <- sqrt(sum((x - mean_x)^2) / (n))\n\n    # z-transform x and assign to z\n    z <- (x - mean_x) / sd_x\n\n    # this is not an evaluation, the result is assigned to skewness\n    skewness <- sum(z^3) / n\n\n    # we need to evaulate skewness\n    # we could write \n    # print(skewness)\n    # or\n    # return(skewness)\n    skewness\n}\n```\n:::\n\n\nLaboratory assay percentage CP values are summarized in @tbl-lab-protein-vals. These are similar to the range of %CP values observed in the literature, indicating an reasonable basis for a chemometric model. The percentage CP values were left-skewed (skewness of -0.29) and two thirds of the samples contained more than 25 g kg ^-1^ CP.\n\n\n::: {#tbl-lab-protein-vals .cell tbl-cap='Summary of Laboratory Assayed CP Values (Percent Dry Matter)'}\n\n```{.r .cell-code .hidden}\nmy_summary <- full_data$crude_protein |> skimr::skim()|> select(c(5:11)) |> \n  mutate_all(round, 1)\nnames(my_summary) <- c(\"mean\", \"sd\", \"minimum\", \"first quartile\", \"median\", \"third quartile\", \"maximum\") |> str_to_title()\n\nknitr::kable(my_summary)\n```\n\n::: {.cell-output-display}\n\n\n| Mean|  Sd| Minimum| First Quartile| Median| Third Quartile| Maximum|\n|----:|---:|-------:|--------------:|------:|--------------:|-------:|\n| 26.1| 2.5|    20.8|           23.9|   26.4|           28.2|    30.8|\n\n\n:::\n:::\n\n\n### Preprocessing methods comparison\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# \nmulti_metric <- metric_set(rmse, rsq, rpiq, rpd)\n\n\n# read data back in to work with it\n\nprep_key <- fread(\"./input_data/final_data_set/preprocessing_key.csv\")\n\nsims_key <- fread(\"./input_data/final_data_set/preprocessing_methods_test.csv\")\n\nlong_form <- merge(sims_key, prep_key, all.x = T)\n\n# now pull the metrics\n\n# long_form[, multi_metric(y, value), by = c(\"id\", \"preproc\")]\n\nsummaries <- long_form |> \n  filter(preproc!=\"second_derivative\") |> \n  group_by(id, preproc) |> \n  multi_metric(y, value)\n\n# # comparing methods over a series of metrics...\n# summaries_with_models <- summaries |> \n#   mutate(id = as.character(id)) |> \n#   nest(data = -.metric) |> \n#   mutate(mod = map(data, ~lme4::lmer(.estimate ~ preproc + (1|id), data = .x)),\n#          ems = map(mod, ~emmeans::emmeans(.x, \"preproc\") |> data.frame())\n#          )\n# \n# summaries_with_models_2 <- summaries_with_models |> \n#   select(1, ems) |> \n#   unnest(ems)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# actually, let's summarize via nlme\n# set our varident\nvf2 <- varIdent(form= ~ 1|preproc)\n\n# define custom contrasts\nfirst_part <- rep(1/7,7)\ncontrast_full <- append(first_part, -1, after = 3)\n\n\ncustom <- list(preprocess_vs_raw = contrast_full)\n\nnlme_summaries <- summaries |> \n  mutate(id = as.character(id)) |> \n  nest(data = -.metric) |> \n  mutate(\n    mod_standard = map(data, ~nlme::lme(.estimate ~ preproc, random = ~1|id, data = .x, method =\"ML\")),\n    \n    mod_varident = map(data, ~nlme::lme(.estimate ~ preproc, random = ~1|id, weights = vf2, data = .x, method =\"ML\")),\n    mod_compare = map2(mod_standard, mod_varident, ~anova(.x, .y)),\n         ems = map(mod_varident, ~emmeans::emmeans(.x, \"preproc\") |>multcomp::cld() |>  data.frame()), \n             ems2 = map(mod_varident, ~emmeans::emmeans(.x, \"preproc\")),\n                        contrast = map(ems2, ~emmeans::contrast(.x, custom))\n                                       )\n\n\n\nnlme_summaries_with_models_2 <- nlme_summaries |> \n  select(1, ems) |> \n  unnest(ems)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# add full names\n\nto_table <- nlme_summaries_with_models_2|> \n  left_join(preproc_key) |> \n  select('Preprocessing Method' = full_name, Metric = .metric, Estimate = emmean, SE) |> \n  mutate(Estimate = paste(format(round(Estimate, 2), nsmall = 2), \"±\", format(round(SE, 3), nsmall = 3)))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(preproc)`\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncontrasts <- nlme_summaries |> \n  select(.metric, contrast) |> \n  transmute(.metric, tidy_contrast = map(contrast, tidy)) |> \n  unnest(tidy_contrast)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# lead_lag summaries\nlead_lag <- nlme_summaries_with_models_2 |> select(1:4) |> \n  arrange(.metric, emmean)%>% \n  group_by(.metric) |> \n  mutate(lagged = lag(emmean)) %>% \n  mutate(pct_change = (emmean - lagged) / lagged)|> \n  mutate(lead = lead(emmean)) %>% \n  mutate(pct_change_lead = (emmean - lead) / lead)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# percent change for contrasts\n\nraw_contrast <- nlme_summaries_with_models_2 |> filter(preproc==\"raw\") |> \n  dplyr::select(1:3) |> \n  left_join(contrasts |> select(1,3,estimated_diff = 5)) |> \n  mutate(percent_difference = estimated_diff/(emmean+estimated_diff))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(.metric)`\n```\n\n\n:::\n:::\n\n\nAll preprocessing methods outperformed untransformed spectral data, as shown in @tbl-preproc. Averaged together, all preprocessed spectra were superior to untransformed spectra, with lower RMSE and higher R^2^, RPD and RPIQ values (significant at $\\alpha$ level \\<0.001). Preprocessing methods had 11.6 % lower RMSE, and had 3.1% higher R^2^, 6.3% higher RPD and 7.4% higher RPIQ than unprocessed spectra. Preprocessed spectra also had lower standard errors than untransformed spectra.\n\nThe SNV-SG method had the lowest RMSE and the highest R^2^, RPD and RPIQ averaging over all iterations. SNV-SG's RMSE was 1.4% lower than the next best preprocessing method (SG), while SNV-SG's R^2^, RPD, and RPIQ were 0.4%, 2.1%, and 2.4% higher than SG respectively. However, the differences between the best and second best methods by metric were only statistically significant at $\\alpha$ \\<0.05 for RPD and RPIQ. There is a long history of using RPD to evaluate chemometric models although the statistic has been criticized as inadequately reflecting the distribution of skewed populations, a situation which RPIQ was designed to address [@bellon-maurel_critical_2010]. In this study, the data were somewhat but not heavily skewed and RPD and RPIQ metrics agreed. The superiority of SNV-SG by these metrics made it the best choice for the final model.\n\n\n::: {#tbl-preproc .cell tbl-cap='Evaluation of Preprocessing Methods by Metric ± Standard Error'}\n\n```{.r .cell-code .hidden}\n# printable table of results\n\nto_table2 <- to_table |> \n  mutate(`Preprocessing Method` = \n           case_match(`Preprocessing Method`,\n             \"Raw Spectra\"~ \"Untransformed Spectra\",\n             .default=`Preprocessing Method`\n           )) |> \n  select(1:3) |> \n  pivot_wider(names_from = Metric, values_from = Estimate) |> \n  arrange(rmse) |> \n  rename(RMSE = rmse, RPIQ = rpiq ) |> \n  select(1,2,3,5,4)\n# names(to_table2)[3] <- \"$^{2}$\"\nto_table2|> \n  knitr::kable(col.names = c(\"Preprocessing Method\", \"RMSE\",  \"$R^{2}$\",\"RPD\", \"RPIQ\"))\n```\n\n::: {.cell-output-display}\n\n\n|Preprocessing Method                             |RMSE         |$R^{2}$      |RPD          |RPIQ         |\n|:------------------------------------------------|:------------|:------------|:------------|:------------|\n|Standard Normal Variate following Savitzky-Golay |1.02 ± 0.012 |0.84 ± 0.004 |2.49 ± 0.032 |3.97 ± 0.076 |\n|Savitzky-Golay                                   |1.03 ± 0.012 |0.83 ± 0.004 |2.44 ± 0.029 |3.88 ± 0.072 |\n|First Derivative                                 |1.07 ± 0.013 |0.82 ± 0.004 |2.36 ± 0.032 |3.77 ± 0.075 |\n|Standard Normal Variate                          |1.12 ± 0.016 |0.80 ± 0.005 |2.26 ± 0.036 |3.61 ± 0.081 |\n|Gap-segment Derivative                           |1.12 ± 0.018 |0.81 ± 0.006 |2.26 ± 0.040 |3.60 ± 0.086 |\n|Standard Normal Variate-Detrend                  |1.13 ± 0.015 |0.80 ± 0.005 |2.22 ± 0.035 |3.55 ± 0.079 |\n|Multiplicative Scatter Correction                |1.17 ± 0.016 |0.79 ± 0.006 |2.17 ± 0.035 |3.47 ± 0.080 |\n|Untransformed Spectra                            |1.22 ± 0.044 |0.79 ± 0.009 |2.17 ± 0.052 |3.42 ± 0.105 |\n\n\n:::\n:::\n\n\nFrom the literature, these results are readily explained. Standard normal variate and SNV-detrend both correct light scatter, which is often a function of differences in particle size and sample packing density, although SNV-detrend is often used for densely-packed, powdered samples [@barnes_standard_1989]. SG is a smoothing filter that regresses on the signal over a series of windows, removing noise while preserving the signal's shape and features [@li_quantitative_2020; @luo_properties_2005]. Derivatives, here including SG, gap-segment, and first derivatives pretreatments may remove additive and multiplicative effects, but not necessarily light scatter; as well, derivatives may increase spectral noise [@rinnan_review_2009]. Here, hemp grain was neither powdered nor densely packed but samples were subject to light scatter and noise due to differences in particle size in the hemp grain.\n\n<!-- The preprocessing methods examined represent a portion of those available. As well, these methods tend to have a number of user-adjustable parameters whose various permutations were not tested. This subset of preprocessing methods and parameters nonetheless contained substantial variations in model quality, demonstrating the importance of selecting an appropriate preprocessing method. -->\n\n### Final model development and summary\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel_n_comp_statistics <- fread(\"./input_data/final_data_set/final_model_n_component_stats.csv\")\n\n# define a function to calculate percent difference\npct_lower <- function(x){\n  my_lag = data.table::shift(x, type = \"lag\")\n  round((x - my_lag)/my_lag*100,2)\n}\n\navg_change <- model_n_comp_statistics[,lapply(.SD, mean),.SDcols = 3:8, by= ncomp]\n\nchange_per_pc <- avg_change[, lapply(.SD, pct_lower), .SDcols = 2:7]\n```\n:::\n\n\nThe model improved most rapidly as the number of components increased from 1 to 7, with the inclusion of each additional component being associated with a decrease in RMSE of 5%-12%. From 8 to 12 components, model performance continued to improve, although gains were more modest (there was a decrease in RMSE of 0.7%-3% with the inclusion of each additional component). With 13 or more components, performance gains were minimal and the relative ranks of the models tended to be stable (@fig-model-calibration).\n\n\n::: {#cell-fig-model-calibration .cell}\n\n```{.r .cell-code .hidden}\nmodel_n_comp_statistics |> \n  ggplot(aes(as.factor(ncomp), RMSE)) + \n  geom_line(aes(group = id), alpha = 0.03) + \n  theme_classic() + \n  xlab(\"Crude Protein Model Number of Components\") + \n  ylab(\"Crude Protein Model Root Mean Squared Error\")\n```\n\n::: {.cell-output-display}\n![Decreasing RMSE with increasing number of components for 1000 training sets](index_files/figure-html/fig-model-calibration-1.png){#fig-model-calibration width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel_final_predictions <- fread(\"./input_data/final_data_set/final_model_predictions.csv\")\n\nfinal_model_table <- model_final_predictions |> \n  group_by(id) |> \n  multi_metric(crude_protein, predicted_crude_protein) |> setDT()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# make a final model table that spreads wide\n\nft2 <- final_model_table[,.estimator:=NULL] |> dcast(id~.metric, value.var = \".estimate\")\n\ncorr_coeffs <- cor(ft2[,2:5])\n\n# id the very worst fits.\nlow_cor_ids <- ft2[rsq<0.7,]$id\n\n\ngreat_mods <- ft2[rpd>3&rpiq>4.1&rsq>0.8,]\n\ngood_mods <- ft2[rpd>2.5&rpd<3&rpiq<4.1&rpiq>2.3&rsq>0.8,]\n\nok_mods <- ft2[rpd>2.0&rpd<2.5&rpiq>2.3,]\n\npoor_but_functional <-  ft2[rpd>1.5&rpd<2,]\n\nall_mods <- list(great_mods, good_mods, ok_mods, poor_but_functional)\n\nfull_sum <- lapply(all_mods, nrow)\n```\n:::\n\n\nThe final models' performances on the test sets were similar, but not identical to, those obtained during the initial comparison of preprocessing methods. The final models' mean RMSE was 1.03, R^2^ was 0.83, RPD was 2.44, and RPIQ was 3.89. Five percent of the models were \"excellent\" for quantitative prediction by both metrics, with RPD \\> 3 and RPIQ \\> 4.1, while an additional 11% of the models were \"good\" by both metrics (RPD range from 2.5\\--3.0, RPIQ range from 2.3\\-- 4.1). Forty-nine percent of the models had the ability to approximate quantitative prediction (RPD range from 2.0\\--2.5), and nine percent of the models were able to distinguish between higher and lower percentage CP values (RPD range from 1.5\\--2.0). Therefore, 74% of the models had, at minimum, the ability to distinguish between high and low values with 65% having, at minimum, the ability to approximate quantitative prediction. Despite the generally good model performance, a subset of poor models can be seen. For example, @fig-final-metric-boxplot shows twenty-one models with R^2^ below 0.7.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nskim_metrics <- final_model_table |> \n  group_by(.metric) |> \n  skimr::skim()\n```\n:::\n\n::: {#cell-fig-final-metric-boxplot .cell}\n\n```{.r .cell-code .hidden}\n# setnames(model_final_predictions, \"V1\", \"crude_protein\")\n\n\n\nfinal_model_table |>\n  mutate(metric2 = toupper(.metric)) |> \n  ggplot(aes(x = .metric, y = .estimate)) + \n  theme_classic() + geom_boxplot() + \n  facet_wrap(nrow = 1,vars(factor(metric2, levels = c(\"RMSE\", \"RSQ\",\"RPD\", \"RPIQ\"))), scales = \"free\") +\n  xlab(\"Metric\") + ylab(\"Estimate\")+\n  theme(\n    axis.title.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank())\n```\n\n::: {.cell-output-display}\n![Final model test set performance (1000 iterations)](index_files/figure-html/fig-final-metric-boxplot-1.png){#fig-final-metric-boxplot width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# add difference calculation between predicted and observed...\nmodel_final_predictions[,difference := predicted_crude_protein - crude_protein]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# my_cut <- cut(spectra_2$crude_protein, 3)\n# cut_dt <- data.table(ith_in_data_set = 1:149, cutpoints = my_cut)\n\n\n# revised_model_cutpoints\ncutpoints2 <- model_final_predictions |> \n  distinct(ith_in_data_set, crude_protein) |> \n  mutate(cutpoints = cut(crude_protein, 3)) |> \n  arrange(crude_protein) |> \n  mutate(plot_order = 1:n())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata_sum_by_sample <- model_final_predictions[,lapply(.SD, mean), .SDcols = c(\"crude_protein\", \"difference\"), by = \"ith_in_data_set\"]\nsetorder(data_sum_by_sample, crude_protein)\ntemp_dat <- copy(data_sum_by_sample)\n# create temporary ith\ntemp_dat[,tmp_ith:= 1:.N]\nmin_val <- min(temp_dat$crude_protein)\n# center this\ntemp_dat[,adj_cp:= crude_protein - min_val]\n\nlm_mod <- lm(difference~adj_cp, data = temp_dat) \nlm_mod_sum <- summary(lm_mod)\n\ncoefs <- coef(lm_mod)\n\npreds <- predict(lm_mod, temp_dat)\nds_preds <- temp_dat[,c(\"ith_in_data_set\")] |> cbind(preds)\n\nds_cutpoints <- merge(ds_preds, cutpoints2)\nsetorder(ds_cutpoints, plot_order)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsd_mod <- model_final_predictions[,list(sd_diff = sd(difference), crude_protein = mean(crude_protein)), by = \"ith_in_data_set\"]\nsetorder(sd_mod, crude_protein)\ntemp_dat_sd <- copy(sd_mod)\n# create temporary ith\ntemp_dat_sd[,tmp_ith:= 1:.N]\nmin_val_sd <- min(temp_dat_sd$crude_protein)\n# center this\ntemp_dat_sd[,adj_cp:= crude_protein - min_val]\n\nlm_mod_sd <- lm(sd_diff~adj_cp, data = temp_dat_sd) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# look at worst samples info...\n\nworst_preds <- model_final_predictions[id%in%low_cor_ids]\n\nworst <- worst_preds[,.N, by = ith_in_data_set][order(N, decreasing = T)][N>8]\n\ntroubles <- merge(worst, full_data[,1:7], all.x = T)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncts <- ds_cutpoints[,mean(preds), by=cutpoints]\n```\n:::\n\n\nFinally, the pattern of test set errors was examined on a per-sample basis by calculating the difference between the actual and predicted values for the samples in the test sets @fig-validation_set_performance. A linear model was fit considering the mean estimated error for each sample where that sample was in the test set as compared to the sample's actual value. The models overestimated percentage CP by approximately 0.5 % in the lowest tertile and underestimated percentage CP by -0.01 % and -0.41 % in the middle and highest tertile, respectively. The variance of the errors did not increase appreciably as percentage CP increased.\n\n\n::: {#cell-fig-validation_set_performance .cell}\n\n```{.r .cell-code .hidden}\n# \n\nmodel_final_predictions |> \n  left_join(cutpoints2) |> \n  mutate(type = \"Actual\") |> \n  arrange(plot_order) |> \n  ggplot(aes(plot_order, crude_protein))+\n  geom_point(aes(plot_order, difference, shape = type), alpha = 0.05) +\n  geom_hline(yintercept = 0, linewidth = 2, lty = 2) +\n  geom_point(data = ds_cutpoints |> mutate(type = \"Predicted\"), aes(plot_order, preds, shape = type))+\n  scale_shape_manual(\"Error Type\", values=c(2,3)) +\n  facet_wrap( ~cutpoints, scales = \"free_x\",\n              labeller = as_labeller(c(\"(20.8,24.1]\" = \"Low CP (20.8 - 24.1%)\",\n                                       \"(24.1,27.5]\"= \"Medium CP (24.2 - 27.5%)\",\n                                       \"(27.5,30.8]\" =\"High CP (27.6-30.8%)\")))+ \n  ylab(\"Crude Protein Predicted Percent Difference\\nfrom Assayed Value\")+\n  theme_classic()+\n  theme(\n    axis.title.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank(), \n    legend.position=c(0.9, 0.8)) + \n  guides(shape= guide_legend(override.aes = list(alpha = 1)))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(crude_protein, ith_in_data_set)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Test set prediction errors on a per-sample basis. Actual sample value set to 0, and samples ranked from least to greatest actual % CP value](index_files/figure-html/fig-validation_set_performance-1.png){#fig-validation_set_performance width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# look\n# read in stuff for supplemental table first\nsupp_tab <- fread(\"./input_data/final_data_set/cultivar_table_clean.csv\")\n\n# read in correct location key\nlocs2 <- fread(\"./input_data/final_data_set/corrected_location_key.csv\")\n\n# sort highest and lowest samples...\ntd2 <- temp_dat[order(abs(difference))]\n\n# sort highest and lowest\ntd3 <- td2[!c(16:134),][,grouping:=rep(c(\"best_predicted_10pct\", \"worst_predicted_10_pct\"), each = 15)]\n\n# incorporate background\n\ntd4_bckgrd <- merge(td3, full_data[,1:7], all.x = T)\n\ntd_5 <- merge( td4_bckgrd,locs2, by.y =\"loc\", by.x= 'loc', all.x = T)\n\n\n# make a prop table.\ntd_5_table <-  with(td_5, table(grouping, loc2))\n\ntest_for_errors <- merge( merge(td2, full_data[,1:7], all.x = T),locs2, by.y =\"loc\", by.x= 'loc', all.x = T)\n\nerror_mod <- lm(abs(difference)~loc2, data = test_for_errors)\n\nerror_by_loc <- emmeans::emmeans(error_mod, \"loc2\") |> multcomp::cld()\n```\n:::\n\n\nThe 15 (10%) best and 15 worst predicted samples as measured by the mean absolute error of prediction were identified and their backgrounds examined. Overall, half of the samples in the data set came from Ithaca, NY (\"Ithaca\"), while 28% were collected from Geneva, NY (\"Geneva\") @tbl-hemp_provenance. However, of the 15 worst-predicted samples, 9 were from Geneva, while 3 of the 15 best-predicted samples were from Geneva (by contrast, 7 of the best-predicted and 5 of the worst-predicted samples came from Ithaca). Overall, samples from Geneva had the highest mean absolute error of prediction among locations, 61% greater than samples from Ithaca and 155% greater than samples from Freeville, NY (the only locations where more than 20 samples were assayed).\n\nThis study is limited in that it represents the creation of one model based upon spectra collected from one machine. NIRS calibrations can be unique to a particular machine, even if the machines compared are of the same model [@reeves_potential_2012]. As well, the calibration and validation sets are relatively small.\n\nThis research showed the promise of the use of NIRS in order to make predictions concerning percentage CP in hemp grain using PLS. Promising preprocessing methods were identified and a model was validated. Further research could refine a percentage CP model by including more samples, particularly by rectifying the class imbalance between Geneva and Ithaca, identifying promising spectral regions, or by examining other predictive methods.\n\n## ACKNOWLEDGMENTS\n\nThis work would not have been possible without the efforts of the field staff, undergraduate, and graduate students who planted, maintained, monitored and harvested these trials.\n\n## CONFLICT OF INTEREST\n\nThe authors declare no conflict of interest.\n\n## ORCID\n\n## SUPPLEMENTAL MATERIAL\n\n\n::: {#tbl-hemp_provenance .cell tbl-cap='Tally of hemp cultivars and locations. Private cultivars are labeled \"Cultivar1\", \"Cultivar2\", etc., while experimental cultivars are labeled \"Experimental1\", \"Experimental2\", etc.'}\n\n```{.r .cell-code .hidden}\nsupp_tab2 <- copy(supp_tab)\n\nsupp_tab2[,Cultivar:=toupper(cultivar2)]\nnames(supp_tab2) <- str_to_title(names(supp_tab2))\n# get one that's sortable\nst3 <- supp_tab2[,c(8,2:7)]\noptions(knitr.kable.NA = '')\nknitr::kable(st3)\n```\n\n::: {.cell-output-display}\n\n\n|Cultivar         | Chazy| Freeville| Geneva| Ithaca| Willsboro| Total|\n|:----------------|-----:|---------:|------:|------:|---------:|-----:|\n|ALTAIR           |      |          |       |      1|          |     1|\n|ANKA             |      |         1|      3|      5|         2|    11|\n|BIALOBRZESKIE    |      |         1|      3|      4|         1|     9|\n|CANDA            |      |         1|      1|      1|          |     3|\n|CFX-1            |      |         1|      2|      5|          |     8|\n|CFX-2            |      |         1|      2|      4|          |     7|\n|CRS-1            |     1|         1|      2|      5|          |     9|\n|CULTIVAR1        |      |         1|       |       |          |     1|\n|CULTIVAR2        |      |          |       |      1|          |     1|\n|CULTIVAR3        |      |          |       |      1|          |     1|\n|CULTIVAR4        |      |          |       |      1|          |     1|\n|EARLINA 8        |      |          |      1|       |          |     1|\n|EXPERIMENTAL1    |      |          |       |      1|          |     1|\n|EXPERIMENTAL2    |      |          |       |      1|          |     1|\n|FELINA 32        |      |         1|      2|      3|          |     6|\n|FUTURA 75        |      |         1|      3|      4|          |     8|\n|GRANDI           |      |         3|      3|      4|          |    10|\n|H-51             |      |          |      1|      2|          |     3|\n|HAN-FN-H         |      |          |       |      1|          |     1|\n|HAN-NW           |      |          |       |      1|          |     1|\n|HELENA           |      |         1|       |       |          |     1|\n|HENOLA           |      |          |       |      2|          |     2|\n|HLESIA           |      |          |       |      3|          |     3|\n|HLIANA           |      |          |      1|      1|          |     2|\n|JOEY             |      |         1|      1|      1|          |     3|\n|KATANI           |      |         2|      3|      4|          |     9|\n|NEBRASKA (FERAL) |     1|          |       |      1|          |     2|\n|PEWTER RIVER     |      |         1|       |       |          |     1|\n|PICOLO           |      |         1|      2|      5|          |     8|\n|PORTUGAL         |      |          |      1|       |          |     1|\n|ROCKY HEMP       |      |          |      1|       |          |     1|\n|STERLING GOLD    |      |          |      1|       |          |     1|\n|SWIFT            |     1|         1|       |      1|          |     3|\n|TYGRA            |      |         1|      3|      4|          |     8|\n|USO-31           |     2|         1|      2|      4|          |     9|\n|WOJKO            |      |         1|      3|      4|          |     8|\n|X-59             |      |         2|       |      1|          |     3|\n|TOTAL            |     5|        24|     41|     76|         3|   149|\n\n\n:::\n:::\n\n\n## OPTIONAL SECTIONS\n\n## REFERENCES\n\n## FIGURES AND TABLES\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}